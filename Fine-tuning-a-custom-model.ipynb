{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd0cf09",
   "metadata": {
    "id": "b6e13eef3f5d",
    "papermill": {
     "duration": 0.008141,
     "end_time": "2025-05-04T14:04:24.572227",
     "exception": false,
     "start_time": "2025-05-04T14:04:24.564086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Copyright 2025 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17b8d6c5",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-05-04T14:04:24.588378Z",
     "iopub.status.busy": "2025-05-04T14:04:24.587961Z",
     "iopub.status.idle": "2025-05-04T14:04:24.593791Z",
     "shell.execute_reply": "2025-05-04T14:04:24.592723Z"
    },
    "id": "d6597b11df14",
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.016198,
     "end_time": "2025-05-04T14:04:24.595899",
     "exception": false,
     "start_time": "2025-05-04T14:04:24.579701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26fce7d",
   "metadata": {
    "id": "4KDIFPAL2EnL",
    "papermill": {
     "duration": 0.007127,
     "end_time": "2025-05-04T14:04:24.610532",
     "exception": false,
     "start_time": "2025-05-04T14:04:24.603405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine tuning a custom model\n",
    "\n",
    "In this notebook Gemini API will be used to fine-tune a custom, task-specific model. Fine-tuning can be used for a variety of tasks from classic NLP problems like entity extraction or summarisation, to creative tasks like stylised generation. You will fine-tune a model to classify the category a piece of text (a newsgroup post) into the category it belongs to (the newsgroup name).\n",
    "\n",
    "This codelab walks you tuning a model with the API. [AI Studio](https://aistudio.google.com/app/tune) also supports creating new tuned models directly in the web UI, allowing you to quickly create and monitor models using data from Google Sheets, Drive or your own files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3aa072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:04:24.627106Z",
     "iopub.status.busy": "2025-05-04T14:04:24.626744Z",
     "iopub.status.idle": "2025-05-04T14:04:44.444041Z",
     "shell.execute_reply": "2025-05-04T14:04:44.442686Z"
    },
    "id": "9wafTyEH1_xF",
    "papermill": {
     "duration": 19.828096,
     "end_time": "2025-05-04T14:04:44.446667",
     "exception": false,
     "start_time": "2025-05-04T14:04:24.618571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip uninstall -qqy jupyterlab  # Remove unused conflicting packages\n",
    "!pip install -U -q \"google-genai==1.7.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecce2f5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:04:44.463424Z",
     "iopub.status.busy": "2025-05-04T14:04:44.462350Z",
     "iopub.status.idle": "2025-05-04T14:04:45.792403Z",
     "shell.execute_reply": "2025-05-04T14:04:45.791324Z"
    },
    "id": "T0CBG9xL2PvT",
    "papermill": {
     "duration": 1.340302,
     "end_time": "2025-05-04T14:04:45.794348",
     "exception": false,
     "start_time": "2025-05-04T14:04:44.454046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "genai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba1557d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:04:45.811844Z",
     "iopub.status.busy": "2025-05-04T14:04:45.810515Z",
     "iopub.status.idle": "2025-05-04T14:04:46.078080Z",
     "shell.execute_reply": "2025-05-04T14:04:46.077180Z"
    },
    "id": "VuJPY3GK2SLZ",
    "papermill": {
     "duration": 0.278511,
     "end_time": "2025-05-04T14:04:46.080365",
     "exception": false,
     "start_time": "2025-05-04T14:04:45.801854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc94e03",
   "metadata": {
    "id": "CqVA5QFO6n4z",
    "papermill": {
     "duration": 0.007016,
     "end_time": "2025-05-04T14:04:46.095059",
     "exception": false,
     "start_time": "2025-05-04T14:04:46.088043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explore available models\n",
    "\n",
    "We will be using the [`TunedModel.create`](https://ai.google.dev/api/tuning#method:-tunedmodels.create) API method to start the fine-tuning job and create custom model. Find a model that supports it through the [`models.list`](https://ai.google.dev/api/models#method:-models.list) endpoint. We can also find more information about tuning models in [the model tuning docs](https://ai.google.dev/gemini-api/docs/model-tuning/tutorial?lang=python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd86a0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:04:46.111911Z",
     "iopub.status.busy": "2025-05-04T14:04:46.111073Z",
     "iopub.status.idle": "2025-05-04T14:04:46.317979Z",
     "shell.execute_reply": "2025-05-04T14:04:46.316782Z"
    },
    "id": "coEacWAB6o0G",
    "papermill": {
     "duration": 0.21817,
     "end_time": "2025-05-04T14:04:46.320673",
     "exception": false,
     "start_time": "2025-05-04T14:04:46.102503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.5-flash-001-tuning\n"
     ]
    }
   ],
   "source": [
    "for model in client.models.list():\n",
    "    if \"createTunedModel\" in model.supported_actions:\n",
    "        print(model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e6f37",
   "metadata": {
    "id": "peFm0w_0c1CO",
    "papermill": {
     "duration": 0.007083,
     "end_time": "2025-05-04T14:04:46.335605",
     "exception": false,
     "start_time": "2025-05-04T14:04:46.328522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Download the dataset\n",
    "\n",
    "The [20 Newsgroups Text Dataset](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) contains 18,000 newsgroups posts on 20 topics divided into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9af2a670",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:04:46.352495Z",
     "iopub.status.busy": "2025-05-04T14:04:46.351473Z",
     "iopub.status.idle": "2025-05-04T14:04:58.798398Z",
     "shell.execute_reply": "2025-05-04T14:04:58.797292Z"
    },
    "id": "bX_kpgnQ9b-Z",
    "papermill": {
     "duration": 12.457881,
     "end_time": "2025-05-04T14:04:58.800611",
     "exception": false,
     "start_time": "2025-05-04T14:04:46.342730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset=\"train\")\n",
    "newsgroups_test = fetch_20newsgroups(subset=\"test\")\n",
    "\n",
    "# View list of class names for dataset\n",
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c02a124",
   "metadata": {
    "id": "ipafe6ptZFjt",
    "papermill": {
     "duration": 0.007242,
     "end_time": "2025-05-04T14:04:58.815695",
     "exception": false,
     "start_time": "2025-05-04T14:04:58.808453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here's what a single row looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89ff4248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:04:58.832467Z",
     "iopub.status.busy": "2025-05-04T14:04:58.832010Z",
     "iopub.status.idle": "2025-05-04T14:04:58.837919Z",
     "shell.execute_reply": "2025-05-04T14:04:58.836876Z"
    },
    "id": "EtEXcdT39hCB",
    "papermill": {
     "duration": 0.017225,
     "end_time": "2025-05-04T14:04:58.840434",
     "exception": false,
     "start_time": "2025-05-04T14:04:58.823209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f66b12",
   "metadata": {
    "id": "03lDs1O4ZQ0-",
    "papermill": {
     "duration": 0.007767,
     "end_time": "2025-05-04T14:04:58.855882",
     "exception": false,
     "start_time": "2025-05-04T14:04:58.848115",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare the dataset\n",
    "\n",
    "This pre-processing removes personal information, which can be used to \"shortcut\" to known users of a forum, and formats the text to appear a bit more like regular text and less like a newsgroup post (e.g. by removing the mail headers). This normalisation allows the model to generalise to regular text and not over-depend on specific fields. If input data is always going to be newsgroup posts, it may be helpful to leave this structure in place if they provide genuine signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f00c5dd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:04:58.873635Z",
     "iopub.status.busy": "2025-05-04T14:04:58.873155Z",
     "iopub.status.idle": "2025-05-04T14:04:59.813201Z",
     "shell.execute_reply": "2025-05-04T14:04:59.812398Z"
    },
    "id": "IoNYTxpoZgB0",
    "papermill": {
     "duration": 0.951589,
     "end_time": "2025-05-04T14:04:59.815631",
     "exception": false,
     "start_time": "2025-05-04T14:04:58.864042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import email\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def preprocess_newsgroup_row(data):\n",
    "    # Extract only the subject and body\n",
    "    msg = email.message_from_string(data)\n",
    "    text = f\"{msg['Subject']}\\n\\n{msg.get_payload()}\"\n",
    "    # Strip any remaining email addresses\n",
    "    text = re.sub(r\"[\\w\\.-]+@[\\w\\.-]+\", \"\", text)\n",
    "    # Truncate the text to fit within the input limits\n",
    "    text = text[:40000]\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_newsgroup_data(newsgroup_dataset):\n",
    "    # Put data points into dataframe\n",
    "    df = pd.DataFrame(\n",
    "        {\"Text\": newsgroup_dataset.data, \"Label\": newsgroup_dataset.target}\n",
    "    )\n",
    "    # Clean up the text\n",
    "    df[\"Text\"] = df[\"Text\"].apply(preprocess_newsgroup_row)\n",
    "    # Match label to target name index\n",
    "    df[\"Class Name\"] = df[\"Label\"].map(lambda l: newsgroup_dataset.target_names[l])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a6e660f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:04:59.832997Z",
     "iopub.status.busy": "2025-05-04T14:04:59.831920Z",
     "iopub.status.idle": "2025-05-04T14:05:03.535313Z",
     "shell.execute_reply": "2025-05-04T14:05:03.534288Z"
    },
    "id": "kvOsUSRWaW4g",
    "papermill": {
     "duration": 3.714181,
     "end_time": "2025-05-04T14:05:03.537439",
     "exception": false,
     "start_time": "2025-05-04T14:04:59.823258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHAT car is this!?\\n\\n I was wondering if anyo...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SI Clock Poll - Final Call\\n\\nA fair number of...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PB questions...\\n\\nwell folks, my mac plus fin...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re: Shuttle Launch Question\\n\\nFrom article &lt;&gt;...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  \\\n",
       "0  WHAT car is this!?\\n\\n I was wondering if anyo...      7   \n",
       "1  SI Clock Poll - Final Call\\n\\nA fair number of...      4   \n",
       "2  PB questions...\\n\\nwell folks, my mac plus fin...      4   \n",
       "3  Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...      1   \n",
       "4  Re: Shuttle Launch Question\\n\\nFrom article <>...     14   \n",
       "\n",
       "              Class Name  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing to training and test datasets\n",
    "df_train = preprocess_newsgroup_data(newsgroups_train)\n",
    "df_test = preprocess_newsgroup_data(newsgroups_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9003bf6e",
   "metadata": {
    "id": "XSKcj5WtadaR",
    "papermill": {
     "duration": 0.007423,
     "end_time": "2025-05-04T14:05:03.552828",
     "exception": false,
     "start_time": "2025-05-04T14:05:03.545405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now sample the data. We will keep 50 rows for each category for training. Note that this is even fewer than the Keras example, as this technique (parameter-efficient fine-tuning, or PEFT) updates a relatively small number of parameters and does not require training a new model or updating the large model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40abe21a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:05:03.569975Z",
     "iopub.status.busy": "2025-05-04T14:05:03.569565Z",
     "iopub.status.idle": "2025-05-04T14:05:03.617384Z",
     "shell.execute_reply": "2025-05-04T14:05:03.616300Z"
    },
    "id": "0t9Xu6X5akkt",
    "papermill": {
     "duration": 0.059314,
     "end_time": "2025-05-04T14:05:03.619889",
     "exception": false,
     "start_time": "2025-05-04T14:05:03.560575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_data(df, num_samples, classes_to_keep):\n",
    "    # Sample rows, selecting num_samples of each Label.\n",
    "    df = (\n",
    "        df.groupby(\"Label\")[df.columns]\n",
    "        .apply(lambda x: x.sample(num_samples))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    df = df[df[\"Class Name\"].str.contains(classes_to_keep)]\n",
    "    df[\"Class Name\"] = df[\"Class Name\"].astype(\"category\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "TRAIN_NUM_SAMPLES = 50\n",
    "TEST_NUM_SAMPLES = 10\n",
    "# Keep rec.* and sci.*\n",
    "CLASSES_TO_KEEP = \"^rec|^sci\"\n",
    "\n",
    "df_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
    "df_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb466555",
   "metadata": {
    "papermill": {
     "duration": 0.007477,
     "end_time": "2025-05-04T14:05:03.635292",
     "exception": false,
     "start_time": "2025-05-04T14:05:03.627815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluate baseline performance\n",
    "\n",
    "Before start tuning a model, it's good practice to perform an evaluation on the available models to ensure measuring how much the tuning helps.\n",
    "\n",
    "First identify a single sample row to use for visual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e59a077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:05:03.652280Z",
     "iopub.status.busy": "2025-05-04T14:05:03.651838Z",
     "iopub.status.idle": "2025-05-04T14:05:03.658204Z",
     "shell.execute_reply": "2025-05-04T14:05:03.657161Z"
    },
    "papermill": {
     "duration": 0.017382,
     "end_time": "2025-05-04T14:05:03.660334",
     "exception": false,
     "start_time": "2025-05-04T14:05:03.642952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need info on 88-89 Bonneville\n",
      "\n",
      "\n",
      " I am a little confused on all of the models of the 88-89 bonnevilles.\n",
      "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
      "differences are far as features or performance. I am also curious to\n",
      "know what the book value is for prefereably the 89 model. And how much\n",
      "less than book value can you usually get them for. In other words how\n",
      "much are they in demand this time of year. I have heard that the mid-spring\n",
      "early summer is the best time to buy.\n",
      "\n",
      "\t\t\tNeil Gandler\n",
      "\n",
      "---\n",
      "Label: rec.autos\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 0\n",
    "sample_row = preprocess_newsgroup_row(newsgroups_test.data[sample_idx])\n",
    "sample_label = newsgroups_test.target_names[newsgroups_test.target[sample_idx]]\n",
    "\n",
    "print(sample_row)\n",
    "print('---')\n",
    "print('Label:', sample_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd59989",
   "metadata": {
    "papermill": {
     "duration": 0.007405,
     "end_time": "2025-05-04T14:05:03.675805",
     "exception": false,
     "start_time": "2025-05-04T14:05:03.668400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Passing the text directly in as a prompt does not yield the desired results. The model will attempt to respond to the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6314c038",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:05:03.692637Z",
     "iopub.status.busy": "2025-05-04T14:05:03.692176Z",
     "iopub.status.idle": "2025-05-04T14:05:07.289370Z",
     "shell.execute_reply": "2025-05-04T14:05:07.288279Z"
    },
    "papermill": {
     "duration": 3.608062,
     "end_time": "2025-05-04T14:05:07.291523",
     "exception": false,
     "start_time": "2025-05-04T14:05:03.683461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're right, there were a lot of different Bonneville trim levels in 1988 and 1989! Let's break them down:\n",
      "\n",
      "**Bonneville Trim Levels:**\n",
      "\n",
      "* **LE (Luxury Edition):**  This was the base model. It featured a 3.8L V6 engine, cloth upholstery, and basic amenities.\n",
      "* **SE (Special Edition):**  This level offered a more luxurious interior with upgraded materials, a slightly more powerful 3.8L V6 engine, and some additional features like power windows and door locks.\n",
      "* **LSE (Luxury Special Edition):**  This trim level added even more luxury and features, including a digital instrument cluster, leather seating, and a more powerful 3.8L V6 engine.\n",
      "* **SSE (Sport Sedan Edition):**  This model focused on performance.  It came with a more powerful 3.8L V6 engine with a higher horsepower rating, a firmer suspension, and sporty styling cues. \n",
      "* **SSEi (Sport Sedan Edition with Injection):**  This was the top-of-the-line performance model.  It featured a fuel-injected 3.8L V6 engine that produced even more power than the SSE, along with upgraded brakes and a stiffer suspension. \n",
      "\n",
      "**Book Value:**\n",
      "\n",
      "Book value is a tricky thing. Websites like Kelley Blue Book (KBB) and Edmunds will give you an idea of what the average price is for a particular model and year. However, actual values can vary depending on condition, mileage, and local market demand.\n",
      "\n",
      "**Negotiation & Seasonality:**\n",
      "\n",
      "You're right, mid-spring to early summer is often a good time to buy cars. Dealerships are eager to clear out inventory to make room for new models. You can typically get a better price than average during this time.  \n",
      "\n",
      "**General Tips for Finding a Deal:**\n",
      "\n",
      "* **Research extensively:** Use online resources like KBB, Edmunds, and Autotrader to compare prices and get a sense of market values.\n",
      "* **Be patient:** Don't rush into a purchase. Take your time to find the right car at the right price.\n",
      "* **Negotiate aggressively:** Be prepared to negotiate and don't be afraid to walk away if you don't get a price you're comfortable with.\n",
      "* **Consider a pre-purchase inspection:**  This can help you avoid buying a car with hidden problems.\n",
      "\n",
      "**Specific to 88-89 Bonnevilles:**\n",
      "\n",
      "These Bonnevilles were popular cars in their day, but they're now considered classic.  Their demand will depend on condition.  A well-maintained, low-mileage model could command a premium, while a higher-mileage car with issues might be more difficult to sell. \n",
      "\n",
      "**Remember, there is no \"magic\" price.** The best way to determine the value of a specific 88-89 Bonneville is to research comparable models in your area and then negotiate a fair price with the seller. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-1.5-flash-001\", contents=sample_row)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0d7270",
   "metadata": {
    "papermill": {
     "duration": 0.007446,
     "end_time": "2025-05-04T14:05:07.307045",
     "exception": false,
     "start_time": "2025-05-04T14:05:07.299599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can use the prompt engineering techniques you have learned this week to induce the model to perform the desired task. Try some of your own ideas and see what is effective, or check out the following cells for different approaches. Note that they have different levels of effectiveness!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d221dcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:05:07.325840Z",
     "iopub.status.busy": "2025-05-04T14:05:07.325069Z",
     "iopub.status.idle": "2025-05-04T14:05:08.797536Z",
     "shell.execute_reply": "2025-05-04T14:05:08.796389Z"
    },
    "papermill": {
     "duration": 1.484803,
     "end_time": "2025-05-04T14:05:08.799979",
     "exception": false,
     "start_time": "2025-05-04T14:05:07.315176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While the message doesn't explicitly state the newsgroup, it's highly likely it originated from **alt.autos.pontiac**. \n",
      "\n",
      "Here's why:\n",
      "\n",
      "* **Subject:** The message is about a specific car model (Bonneville), making it relevant to an automotive-focused newsgroup.\n",
      "* **Content:** The message discusses model variations, features, and pricing, which are common topics in car enthusiast forums.\n",
      "* **Specificity:**  The reference to specific trim levels (LE, SE, LSE, SSE, SSEi) suggests familiarity with Pontiac Bonneville details, making an enthusiast forum a strong possibility.\n",
      "* **Popularity:**  alt.autos.pontiac was a popular newsgroup for Pontiac owners and enthusiasts during that time.\n",
      "\n",
      "While other automotive newsgroups might have touched upon the topic, alt.autos.pontiac would have been the most appropriate and likely origin of this message. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ask the model directly in a zero-shot prompt.\n",
    "\n",
    "prompt = \"From what newsgroup does the following message originate?\"\n",
    "baseline_response = client.models.generate_content(\n",
    "    model=\"gemini-1.5-flash-001\",\n",
    "    contents=[prompt, sample_row])\n",
    "print(baseline_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f55933",
   "metadata": {
    "papermill": {
     "duration": 0.007683,
     "end_time": "2025-05-04T14:05:08.816032",
     "exception": false,
     "start_time": "2025-05-04T14:05:08.808349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This technique still produces quite a verbose response. You could try and parse out the relevant text, or refine the prompt even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7fcb04e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:05:08.833966Z",
     "iopub.status.busy": "2025-05-04T14:05:08.833126Z",
     "iopub.status.idle": "2025-05-04T14:05:09.479782Z",
     "shell.execute_reply": "2025-05-04T14:05:09.478472Z"
    },
    "papermill": {
     "duration": 0.658185,
     "end_time": "2025-05-04T14:05:09.482209",
     "exception": false,
     "start_time": "2025-05-04T14:05:08.824024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos.misc\n",
      "\n",
      "Incorrect.\n"
     ]
    }
   ],
   "source": [
    "from google.api_core import retry\n",
    "\n",
    "# You can use a system instruction to do more direct prompting, and get a\n",
    "# more succinct answer.\n",
    "\n",
    "system_instruct = \"\"\"\n",
    "You are a classification service. You will be passed input that represents\n",
    "a newsgroup post and you must respond with the newsgroup from which the post\n",
    "originates.\n",
    "\"\"\"\n",
    "\n",
    "# Define a helper to retry when per-minute quota is reached.\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "# If you want to evaluate your own technique, replace this body of this function\n",
    "# with your model, prompt and other code and return the predicted answer.\n",
    "@retry.Retry(predicate=is_retriable)\n",
    "def predict_label(post: str) -> str:\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-1.5-flash-001\",\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=system_instruct),\n",
    "        contents=post)\n",
    "\n",
    "    rc = response.candidates[0]\n",
    "\n",
    "    # Any errors, filters, recitation, etc we can mark as a general error\n",
    "    if rc.finish_reason.name != \"STOP\":\n",
    "        return \"(error)\"\n",
    "    else:\n",
    "        # Clean up the response.\n",
    "        return response.text.strip()\n",
    "\n",
    "\n",
    "prediction = predict_label(sample_row)\n",
    "\n",
    "print(prediction)\n",
    "print()\n",
    "print(\"Correct!\" if prediction == sample_label else \"Incorrect.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3790ed88",
   "metadata": {
    "papermill": {
     "duration": 0.008307,
     "end_time": "2025-05-04T14:05:09.498698",
     "exception": false,
     "start_time": "2025-05-04T14:05:09.490391",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now run a short evaluation using the function defined above. The test set is further sampled to ensure the experiment runs smoothly on the API's free tier. In practice evaluate over the whole set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab306518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:05:09.516851Z",
     "iopub.status.busy": "2025-05-04T14:05:09.516461Z",
     "iopub.status.idle": "2025-05-04T14:06:00.964390Z",
     "shell.execute_reply": "2025-05-04T14:06:00.963269Z"
    },
    "papermill": {
     "duration": 51.460098,
     "end_time": "2025-05-04T14:06:00.967104",
     "exception": false,
     "start_time": "2025-05-04T14:05:09.507006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73332ceff560422d9fbb3dafd3d96a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 31.25%\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from tqdm.rich import tqdm as tqdmr\n",
    "import warnings\n",
    "\n",
    "# Enable tqdm features on Pandas.\n",
    "tqdmr.pandas()\n",
    "\n",
    "# But suppress the experimental warning\n",
    "warnings.filterwarnings(\"ignore\", category=tqdm.TqdmExperimentalWarning)\n",
    "\n",
    "\n",
    "# Further sample the test data to be mindful of the free-tier quota.\n",
    "df_baseline_eval = sample_data(df_test, 2, '.*')\n",
    "\n",
    "# Make predictions using the sampled data.\n",
    "df_baseline_eval['Prediction'] = df_baseline_eval['Text'].progress_apply(predict_label)\n",
    "\n",
    "# And calculate the accuracy.\n",
    "accuracy = (df_baseline_eval[\"Class Name\"] == df_baseline_eval[\"Prediction\"]).sum() / len(df_baseline_eval)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae33e36",
   "metadata": {
    "papermill": {
     "duration": 0.013057,
     "end_time": "2025-05-04T14:06:00.992285",
     "exception": false,
     "start_time": "2025-05-04T14:06:00.979228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now take a look at the dataframe to compare the predictions with the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dd5d89d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:06:02.445564Z",
     "iopub.status.busy": "2025-05-04T14:06:02.445305Z",
     "iopub.status.idle": "2025-05-04T14:06:02.456847Z",
     "shell.execute_reply": "2025-05-04T14:06:02.455949Z"
    },
    "papermill": {
     "duration": 1.452885,
     "end_time": "2025-05-04T14:06:02.458781",
     "exception": false,
     "start_time": "2025-05-04T14:06:01.005896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Re: MR2 - noisy engine.\\n\\n\\n&gt;Eliot is right a...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>rec.autos.toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Domestic Content of US/Japan Joint Ventures\\n\\...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>rec.autos.imported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Re: Your opinion and what it means to me.\\n\\nI...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Kinder, Gentler BMW Mailing List\\n\\nI know t...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>rec.autos.bmw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re: A rooky question about the ERA\\n\\nThomas T...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Re: bosio's no-hitter\\n\\nIn article &lt;&gt;  writes...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hockeytipset 93 avgjort\\n\\n\\n\\n\\t         Hock...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Re: LIST OF TEE TIMES AT METROPOLITAN TORONTO ...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Re: Overreacting (was Re: Once tapped, your co...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>comp.society.privacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Re: PGP Where to get it?\\n\\nJeff Hupp () wrote...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>(error)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Re: How to the disks copy protected.\\n\\nIn art...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>how to get rid of flyback whine?\\n\\nI recently...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>rec.audio.video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Re: cure for dry skin?\\n\\nI cured mine with Ba...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>alt.folklore.urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Patti Duke's Problem\\n\\nDoes anyone have infor...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Re: HST Servicing Mission Scheduled for 11 Day...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>space.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Solid state vs. tube/analog\\n\\n Davis Nicoll s...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>rec.audio.music.classical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  Label  \\\n",
       "0   Re: MR2 - noisy engine.\\n\\n\\n>Eliot is right a...      7   \n",
       "1   Domestic Content of US/Japan Joint Ventures\\n\\...      7   \n",
       "2   Re: Your opinion and what it means to me.\\n\\nI...      8   \n",
       "3   A Kinder, Gentler BMW Mailing List\\n\\nI know t...      8   \n",
       "4   Re: A rooky question about the ERA\\n\\nThomas T...      9   \n",
       "5   Re: bosio's no-hitter\\n\\nIn article <>  writes...      9   \n",
       "6   Hockeytipset 93 avgjort\\n\\n\\n\\n\\t         Hock...     10   \n",
       "7   Re: LIST OF TEE TIMES AT METROPOLITAN TORONTO ...     10   \n",
       "8   Re: Overreacting (was Re: Once tapped, your co...     11   \n",
       "9   Re: PGP Where to get it?\\n\\nJeff Hupp () wrote...     11   \n",
       "10  Re: How to the disks copy protected.\\n\\nIn art...     12   \n",
       "11  how to get rid of flyback whine?\\n\\nI recently...     12   \n",
       "12  Re: cure for dry skin?\\n\\nI cured mine with Ba...     13   \n",
       "13  Patti Duke's Problem\\n\\nDoes anyone have infor...     13   \n",
       "14  Re: HST Servicing Mission Scheduled for 11 Day...     14   \n",
       "15  Solid state vs. tube/analog\\n\\n Davis Nicoll s...     14   \n",
       "\n",
       "            Class Name                 Prediction  \n",
       "0            rec.autos           rec.autos.toyota  \n",
       "1            rec.autos         rec.autos.imported  \n",
       "2      rec.motorcycles            rec.motorcycles  \n",
       "3      rec.motorcycles              rec.autos.bmw  \n",
       "4   rec.sport.baseball         rec.sport.baseball  \n",
       "5   rec.sport.baseball         rec.sport.baseball  \n",
       "6     rec.sport.hockey           rec.sport.hockey  \n",
       "7     rec.sport.hockey           rec.sport.hockey  \n",
       "8            sci.crypt       comp.society.privacy  \n",
       "9            sci.crypt                    (error)  \n",
       "10     sci.electronics   comp.sys.ibm.pc.hardware  \n",
       "11     sci.electronics            rec.audio.video  \n",
       "12             sci.med         alt.folklore.urban  \n",
       "13             sci.med         talk.politics.guns  \n",
       "14           sci.space                 space.misc  \n",
       "15           sci.space  rec.audio.music.classical  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85908ca",
   "metadata": {
    "id": "Ok7ugrLzcghX",
    "papermill": {
     "duration": 0.008594,
     "end_time": "2025-05-04T14:06:02.476459",
     "exception": false,
     "start_time": "2025-05-04T14:06:02.467865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tune a custom model\n",
    "\n",
    "In this example tuning is used to create a model that requires no prompting or system instructions and outputs succinct text from the classes you provide in the training data.\n",
    "\n",
    "The data contains both input text (the processed posts) and output text (the category, or newsgroup), that can use to start tuning a model.\n",
    "\n",
    "When calling `tune()`,  can specify model tuning hyperparameters too:\n",
    " - `epoch_count`: defines how many times to loop through the data,\n",
    " - `batch_size`: defines how many rows to process in a single step, and\n",
    " - `learning_rate`: defines the scaling factor for updating model weights at each step.\n",
    "\n",
    "We can also choose to omit them and use the defaults. [Learn more](https://developers.google.com/machine-learning/crash-course/linear-regression/hyperparameters) about these parameters and how they work. For this example these parameters were selected by running some tuning jobs and selecting parameters that converged efficiently.\n",
    "\n",
    "This example will start a new tuning job, but only if one does not already exist. This allows to leave this codelab and come back later - re-running this step will find your last model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98edeba7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:06:02.495948Z",
     "iopub.status.busy": "2025-05-04T14:06:02.495579Z",
     "iopub.status.idle": "2025-05-04T14:06:02.686547Z",
     "shell.execute_reply": "2025-05-04T14:06:02.685508Z"
    },
    "id": "pWOZlspfY8dV",
    "papermill": {
     "duration": 0.203239,
     "end_time": "2025-05-04T14:06:02.688775",
     "exception": false,
     "start_time": "2025-05-04T14:06:02.485536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing tuned model to reuse.\n",
      "tunedModels/newsgroup-classification-model-mj0pjrl7h\n"
     ]
    }
   ],
   "source": [
    "from collections.abc import Iterable\n",
    "import random\n",
    "\n",
    "\n",
    "# Convert the data frame into a dataset suitable for tuning.\n",
    "input_data = {'examples': \n",
    "    df_train[['Text', 'Class Name']]\n",
    "      .rename(columns={'Text': 'textInput', 'Class Name': 'output'})\n",
    "      .to_dict(orient='records')\n",
    " }\n",
    "\n",
    "# If you are re-running this lab, add your model_id here.\n",
    "model_id = None\n",
    "\n",
    "# Or try and find a recent tuning job.\n",
    "if not model_id:\n",
    "  queued_model = None\n",
    "  # Newest models first.\n",
    "  for m in reversed(client.tunings.list()):\n",
    "    # Only look at newsgroup classification models.\n",
    "    if m.name.startswith('tunedModels/newsgroup-classification-model'):\n",
    "      # If there is a completed model, use the first (newest) one.\n",
    "      if m.state.name == 'JOB_STATE_SUCCEEDED':\n",
    "        model_id = m.name\n",
    "        print('Found existing tuned model to reuse.')\n",
    "        break\n",
    "\n",
    "      elif m.state.name == 'JOB_STATE_RUNNING' and not queued_model:\n",
    "        # If there's a model still queued, remember the most recent one.\n",
    "        queued_model = m.name\n",
    "  else:\n",
    "    if queued_model:\n",
    "      model_id = queued_model\n",
    "      print('Found queued model, still waiting.')\n",
    "\n",
    "\n",
    "# Upload the training data and queue the tuning job.\n",
    "if not model_id:\n",
    "    tuning_op = client.tunings.tune(\n",
    "        base_model=\"models/gemini-1.5-flash-001-tuning\",\n",
    "        training_dataset=input_data,\n",
    "        config=types.CreateTuningJobConfig(\n",
    "            tuned_model_display_name=\"Newsgroup classification model\",\n",
    "            batch_size=16,\n",
    "            epoch_count=2,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    print(tuning_op.state)\n",
    "    model_id = tuning_op.name\n",
    "\n",
    "print(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9fee8a",
   "metadata": {
    "id": "NQ3YZ2MBubCY",
    "papermill": {
     "duration": 0.00838,
     "end_time": "2025-05-04T14:06:02.705788",
     "exception": false,
     "start_time": "2025-05-04T14:06:02.697408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This has created a tuning job that will run in the background. To inspect the progress of the tuning job, run this cell to plot the current status and loss curve. Once the status reaches `ACTIVE`, tuning is complete and the model is ready to use.\n",
    "\n",
    "Tuning jobs are queued, so it may look like no training steps have been taken initially but it will progress. Tuning can take anywhere from a few minutes to multiple hours, depending on factors like your dataset size and how busy the tuning infrastrature is. \n",
    "It is safe to stop this cell at any point. It will not stop the tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "269f572d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:06:02.725142Z",
     "iopub.status.busy": "2025-05-04T14:06:02.724772Z",
     "iopub.status.idle": "2025-05-04T14:06:03.029601Z",
     "shell.execute_reply": "2025-05-04T14:06:03.028444Z"
    },
    "id": "c4ef5f13692d",
    "papermill": {
     "duration": 0.316783,
     "end_time": "2025-05-04T14:06:03.031641",
     "exception": false,
     "start_time": "2025-05-04T14:06:02.714858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! The model state is: JOB_STATE_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "MAX_WAIT = datetime.timedelta(minutes=10)\n",
    "\n",
    "while not (tuned_model := client.tunings.get(name=model_id)).has_ended:\n",
    "\n",
    "    print(tuned_model.state)\n",
    "    time.sleep(60)\n",
    "\n",
    "    # Don't wait too long. Use a public model if this is going to take a while.\n",
    "    if datetime.datetime.now(datetime.timezone.utc) - tuned_model.create_time > MAX_WAIT:\n",
    "        print(\"Taking a shortcut, using a previously prepared model.\")\n",
    "        model_id = \"tunedModels/newsgroup-classification-model-ltenbi1b\"\n",
    "        tuned_model = client.tunings.get(name=model_id)\n",
    "        break\n",
    "\n",
    "\n",
    "print(f\"Done! The model state is: {tuned_model.state.name}\")\n",
    "\n",
    "if not tuned_model.has_succeeded and tuned_model.error:\n",
    "    print(\"Error:\", tuned_model.error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d30471",
   "metadata": {
    "id": "9-qiIdK4u80z",
    "papermill": {
     "duration": 0.008805,
     "end_time": "2025-05-04T14:06:03.049390",
     "exception": false,
     "start_time": "2025-05-04T14:06:03.040585",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Use the new model\n",
    "\n",
    "Now that we have a tuned model, try it out with custom data. We use the same API as a normal Gemini API interaction, but specify new model as the model name, which will start with `tunedModels/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79c85adf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:06:03.068611Z",
     "iopub.status.busy": "2025-05-04T14:06:03.068194Z",
     "iopub.status.idle": "2025-05-04T14:06:04.009374Z",
     "shell.execute_reply": "2025-05-04T14:06:04.008200Z"
    },
    "id": "hyO2-MXLvM6a",
    "papermill": {
     "duration": 0.953409,
     "end_time": "2025-05-04T14:06:04.011475",
     "exception": false,
     "start_time": "2025-05-04T14:06:03.058066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sci.space\n"
     ]
    }
   ],
   "source": [
    "new_text = \"\"\"\n",
    "First-timer looking to get out of here.\n",
    "\n",
    "Hi, I'm writing about my interest in travelling to the outer limits!\n",
    "\n",
    "What kind of craft can I buy? What is easiest to access from this 3rd rock?\n",
    "\n",
    "Let me know how to do that please.\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=model_id, contents=new_text)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43691d74",
   "metadata": {
    "id": "xajLek9DySH_",
    "papermill": {
     "duration": 0.012039,
     "end_time": "2025-05-04T14:06:04.033564",
     "exception": false,
     "start_time": "2025-05-04T14:06:04.021525",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "We can see that the model outputs labels that correspond to those in the training data, and without any system instructions or prompting, which is already a great improvement. Now see how well it performs on the test set.\n",
    "\n",
    "Note that there is no parallelism in this example; classifying the test sub-set will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88e7aa52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:06:04.053362Z",
     "iopub.status.busy": "2025-05-04T14:06:04.052965Z",
     "iopub.status.idle": "2025-05-04T14:07:53.057187Z",
     "shell.execute_reply": "2025-05-04T14:07:53.055890Z"
    },
    "id": "6T2Y3ZApvbMw",
    "papermill": {
     "duration": 109.016606,
     "end_time": "2025-05-04T14:07:53.059347",
     "exception": false,
     "start_time": "2025-05-04T14:06:04.042741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7661df74d5094a6d960363d021c7bd1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "@retry.Retry(predicate=is_retriable)\n",
    "def classify_text(text: str) -> str:\n",
    "    \"\"\"Classify the provided text into a known newsgroup.\"\"\"\n",
    "    response = client.models.generate_content(\n",
    "        model=model_id, contents=text)\n",
    "    rc = response.candidates[0]\n",
    "\n",
    "    # Any errors, filters, recitation, etc we can mark as a general error\n",
    "    if rc.finish_reason.name != \"STOP\":\n",
    "        return \"(error)\"\n",
    "    else:\n",
    "        return rc.content.parts[0].text\n",
    "\n",
    "\n",
    "# The sampling here is just to minimise your quota usage. If you can, you should\n",
    "# evaluate the whole test set with `df_model_eval = df_test.copy()`.\n",
    "df_model_eval = sample_data(df_test, 4, '.*')\n",
    "\n",
    "df_model_eval[\"Prediction\"] = df_model_eval[\"Text\"].progress_apply(classify_text)\n",
    "\n",
    "accuracy = (df_model_eval[\"Class Name\"] == df_model_eval[\"Prediction\"]).sum() / len(df_model_eval)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da1e258",
   "metadata": {
    "papermill": {
     "duration": 0.013514,
     "end_time": "2025-05-04T14:07:53.086879",
     "exception": false,
     "start_time": "2025-05-04T14:07:53.073365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Compare token usage\n",
    "\n",
    "AI Studio and the Gemini API provide model tuning at no cost, however normal limits and charges apply for *use* of a tuned model.\n",
    "\n",
    "The size of the input prompt and other generation config like system instructions, as well as the number of generated output tokens, all contribute to the overall cost of a request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "349ceb2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:07:56.073362Z",
     "iopub.status.busy": "2025-05-04T14:07:56.073035Z",
     "iopub.status.idle": "2025-05-04T14:07:56.283716Z",
     "shell.execute_reply": "2025-05-04T14:07:56.282585Z"
    },
    "papermill": {
     "duration": 3.184585,
     "end_time": "2025-05-04T14:07:56.285732",
     "exception": false,
     "start_time": "2025-05-04T14:07:53.101147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System instructed baseline model: 172 (input)\n",
      "Tuned model: 136 (input)\n",
      "Token savings: 26.47%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the *input* cost of the baseline model with system instructions.\n",
    "sysint_tokens = client.models.count_tokens(\n",
    "    model='gemini-1.5-flash-001', contents=[system_instruct, sample_row]\n",
    ").total_tokens\n",
    "print(f'System instructed baseline model: {sysint_tokens} (input)')\n",
    "\n",
    "# Calculate the input cost of the tuned model.\n",
    "tuned_tokens = client.models.count_tokens(model=tuned_model.base_model, contents=sample_row).total_tokens\n",
    "print(f'Tuned model: {tuned_tokens} (input)')\n",
    "\n",
    "savings = (sysint_tokens - tuned_tokens) / tuned_tokens\n",
    "print(f'Token savings: {savings:.2%}')  # Note that this is only n=1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21774faf",
   "metadata": {
    "papermill": {
     "duration": 0.009461,
     "end_time": "2025-05-04T14:07:56.304627",
     "exception": false,
     "start_time": "2025-05-04T14:07:56.295166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The earlier verbose model also produced more output tokens than needed for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ce5aee0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:07:56.324606Z",
     "iopub.status.busy": "2025-05-04T14:07:56.324167Z",
     "iopub.status.idle": "2025-05-04T14:07:57.063720Z",
     "shell.execute_reply": "2025-05-04T14:07:57.062621Z"
    },
    "papermill": {
     "duration": 0.752127,
     "end_time": "2025-05-04T14:07:57.065945",
     "exception": false,
     "start_time": "2025-05-04T14:07:56.313818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (verbose) output tokens: 186\n",
      "Tuned output tokens: 3\n"
     ]
    }
   ],
   "source": [
    "baseline_token_output = baseline_response.usage_metadata.candidates_token_count\n",
    "print('Baseline (verbose) output tokens:', baseline_token_output)\n",
    "\n",
    "tuned_model_output = client.models.generate_content(\n",
    "    model=model_id, contents=sample_row)\n",
    "tuned_tokens_output = tuned_model_output.usage_metadata.candidates_token_count\n",
    "print('Tuned output tokens:', tuned_tokens_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc78a37",
   "metadata": {
    "id": "6c1204a5d0ab",
    "papermill": {
     "duration": 0.009449,
     "end_time": "2025-05-04T14:07:57.084968",
     "exception": false,
     "start_time": "2025-05-04T14:07:57.075519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Next steps\n",
    "\n",
    "Learn about [when supervised fine-tuning is most effective](https://cloud.google.com/blog/products/ai-machine-learning/supervised-fine-tuning-for-gemini-llm).\n",
    "\n",
    "And check out the [fine-tuning tutorial](https://ai.google.dev/gemini-api/docs/model-tuning/tutorial?hl=en&lang=python) for another example that shows a tuned model extending beyond the training data to new, unseen inputs."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "day-4-fine-tuning-a-custom-model.ipynb",
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 217.158451,
   "end_time": "2025-05-04T14:07:58.017796",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-04T14:04:20.859345",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "39e01526b6f948769b3c4b0d53f40185": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "58733aaa41d247ad9a50a03b527b751f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "73332ceff560422d9fbb3dafd3d96a36": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_58733aaa41d247ad9a50a03b527b751f",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\"></span> <span style=\"color: #008000; text-decoration-color: #008000\">16/16 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:51</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">5 it/s</span> ]\n</pre>\n",
          "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m\u001b[0m \u001b[32m16/16 \u001b[0m [ \u001b[33m0:00:51\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m5 it/s\u001b[0m ]\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "7661df74d5094a6d960363d021c7bd1b": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_39e01526b6f948769b3c4b0d53f40185",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\"></span> <span style=\"color: #008000; text-decoration-color: #008000\">32/32 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:01:48</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">1 it/s</span> ]\n</pre>\n",
          "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m\u001b[0m \u001b[32m32/32 \u001b[0m [ \u001b[33m0:01:48\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m1 it/s\u001b[0m ]\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
